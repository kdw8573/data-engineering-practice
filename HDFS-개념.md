- [HDFS 개념](#hdfs-개념)
  - [HDFS란](#hdfs란)
  - [HDFS 특징](#hdfs-특징)
  - [HDFS Architecture](#hdfs-architecture)
  - [실행 모드](#실행-모드)
  - [HDFS Read/Write](#hdfs-readwrite)
  - [NameNode](#namenode)
  - [HDFS Federation](#hdfs-federation)
  - [Block](#block)
  - [DataNode](#datanode)
  - [HDFS 고가용성](#hdfs-고가용성)
  - [HDFS balancer](#hdfs-balancer)
  - [HDFS File Format](#hdfs-file-format)

# HDFS 개념

![ecosystem-1](https://open.oss.navercorp.com/storage/user/1981/files/ad676b72-4790-45a5-92e1-bbc195dab39e)

## HDFS란
* Hadoop Distributed File System(HDFS)은 대용량 파일을 분산된 서버에 저장하고, 관리하는 파일 시스템.
* 예전에 대용량 파일시스템을 구성하기 위해서 고성능의 서버나 대용량 외장 스토리지가 필요했고, 관리하는 데이터가 커짐에 따라 파일시스템에 필요한 하드웨어 비용이 크게 증가.
* 구글에서 Google File System(GFS) 모델을 설계. 저사양의 컴퓨터(서버) 여러개를 네트워크로 연결시켜 하나의 스토리지처럼 사용하는 모델이였고, 더크 커팅이 GFS 모델을 이용해 HDFS 개발.

## HDFS 특징
* 서버를 구성하는 개별 하드웨어 성능에 관계없이 블록 단위로 data를 저장히기 때문에, 매우 큰 data를 저장하는 것이 가능.
* 여러 node로 구성되어서 노드 수를 늘이는 scale-out을 통해 쉽게 확장 할 수 있음.
* 장애 복구를 위해 블록을 복제하여 저장할 수 있음. 블록에 문제가 생기면 복제한 블록을 통해 데이터 복구.
* 특정 파일을 하나 읽는 것보다 전체 데이터를 읽는 것이 중요하기에 순차적 읽기 방식의 데이터 접근. 그래서 데이터 하나를 읽는 것은 느리지만, 전체적인 데이터 읽기는 빠름.
* 데이터를 한 번 쓰면 여러 번 읽는 것을 목적으로 하기에, 파일 수정을 제한하였고 그로 인해 동작이 단순해지면서 읽기 속도가 높음.

## HDFS Architecture
* master-slave 구조. 하나의 NameNode에 여러 개의 DataNode로 구성.
* 네임노드: 데이터들의 위치, 권한 등 다양한 정보(메타데이터)들을 네임노드에 저장 및 데이터노드 관리.
* 데이터노드: HDFS에 저장되는 데이터를 블록 단위로 쪼개져서 다른 DataNode들에 저장.
* 사용자는 HDFS에 있는 파일을 읽거나 새로 쓸 때 네임노드를 통해 정보를 얻은 후 데이터노드에 접근
![hadoop architecture](https://open.oss.navercorp.com/storage/user/1981/files/7928957f-6abb-45c7-bd78-7c26a226bcf6)

## 실행 모드
* Standalone 모드: 로컬 모드라고도 불림. 하둡에서 제공하는 데몬을 구동하지 않아 분산환경을 고려한 테스트는 불가. 단순히 맵리듀스 프로그램을 개발, 디버깅하는 용도.
* Pseudo-distributed 모드: 하나의 장비에 모든 하둡 환경설정. HDFS와 맵리듀스와 관련된 데몬을 하나의 장비에서만 실행(datanode, namenode 등). 작은 규모의 클러스터에서 실행하는 것 같은 효과.
* Fully distributed 모드: 하둡 데몬을 여러 대의 머신으로 구성된 클러스터에서 실행.

## HDFS Read/Write
* HDFS에서 파일을 읽을 때 일어나는 과정 
> 1. Client가 NameNode에게 파일의 위치를 요청.
> 2. 데이터의 메타데이터를 가지고 있는 NameNode는 Client에게 DataNode의 위치를 반환.
> 3. DataNode의 위치를 받은 Client는 DataNode에 직접 read.
* HDFS에 파일을 쓸 때 일어나는 과정
> 1. Client가 NameNode에게 파일의 block 및 복제본들을 저장할 DataNode의 위치를 요청.
> 2. NameNode는 네트워크 거리를 최소로 하는 DataNode 리스트를 Client에게 반환.
> 3. Client가 block에 데이터를 write 하면 DataNode 리스트가 pipeline을 형성하며 순차적으로 복제본이 write 됨.

## NameNode
* 메타데이터: 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자, 블록의 정보. 각 데이터노드가 전달하는 메타데이터를 받아 전체 노드의 정보를 묶어서 관리. 메모리에서 메타데이터를 관리해서 서버가 꺼지면 메타 데이터가 사라짐. 그래서 서버를 재기동해도 메타데이터를 관리할 수 있도록 2가지 파일 종류가 존재.
> * Fsimage 파일: 네임스페이스(파일 이름, 권한, access time) 정보로, 파일 시스템 이미지.
> * Editlog 파일: 파일 생성, 삭제에 관한 트랜잭션 로그. 메모리에 로그를 저장하다가 주기적으로 파일로 생성.
> * 기존에 존재하던 Fsimage에서 메타데이터가 변경되면 새로운 Fsimage를 만들지않고, 트랜잭션 로그를 기록한 Editlog 파일 생성. 
* 버전1에서 네임노드가 하나만 동작하므로 edits 파일 용량 관리와 장애 복구를 위해 `Secondary NameNode` 사용. 
> * 주기적으로 NameNode에서 fsimage와 edits를 받아 합치고, HDFS에 대한 갱신 내용을 반영한 새로운 fsimage를 생성(CheckPoint). checkpoint 주기는 hdfs 설정에 따라 특정 기간 또는 트랜잭션 수로 결정.
> * 새로 생성한 Fsimage를 NameNode로 전송. Fsimage에 적용 완료한 edits를 삭제함으로써 디스크 공간 절약.
> * 어느 정도 시간차를 두고 보조 네임노드로 복제되기 때문에 주 네임노드에 장애가 발생했을 시 어느 정도의 데이터 손실을 불가피.
* 데이터노드가 주기적으로 전달(3초)하는 하트비트를 통해 데이터노드 동작 상태를 파악. 하트비트가 오지않으면 더이상 파일 IO가 발생하지 않도록 함.
* 데이터노드에서 보낸 블록리포트(데이터노드에 저장된 블록 목록, 각 블록의 저장위치)와 FsImage를 메모리에 올려 관리.
* 클라이언트의 요청 접수.

![hdfs checkpoint](https://open.oss.navercorp.com/storage/user/1981/files/eef17610-6146-4d04-95d3-2494d8dc82d0)

## HDFS Federation
* 네임노드는 파일 메타데이터를 메모리에서 관리. 파일이 많아지면 메모리 사용량이 늘어나게 되고 네임노드의 메모리를 다 쓰면 더이상 파일을 저장 못 함.
* 버전2부터 Federation 개념 도입. 디렉토리(네임스페이스) 단위로 네임노드를 등록하여 사용하는 것. 
* 예를 들어 user, hadoop, tmp 세개의 디렉토리가 존재할 때, /user, /hadoop, /tmp 디렉토리 단위로 총 3개의 네임노드를 실행하여 파일을 관리.
* 파일, 디렉토리의 정보를 가지는 네임스페이스와 블록의 정보를 가지는 블록 풀을 각 네임노드가 독립적으로 관리.
* 네임스페이스와 블록풀을 합쳐 네임스페이스 볼륨이라고 부름. 네임스페이스 볼륨은 독립적으로 관리되기 때문에 하나의 네임노드에 문제가 생겨도 다른 네임노드에 영향 안 줌.
![federation](https://open.oss.navercorp.com/storage/user/1981/files/3b0bcaf1-282c-4781-b934-2f30d5fd7a0f)

## Block 
* HDFS는 블록 구조의 파일시스템. HDFS에 저장하는 파일은 특정 크기의 블록으로 분할되어 분산된 서버에 저장.
* 기본적으로 블록 사이즈는 128MB. 사이즈가 큰 이유는 탐색 비용을 최소화하기 위함. 블록이 크면 하드디스크에서 블록의 시작점을 탐색하는 데 걸리는 시간을 줄이고, 네트워크를 통해 데이터를 전송하는데 더 많은 시간을 할당할 수 있음.
* 블록 크기보다 작은 파일은 실제 파일 크기의 블록으로 저장.  
* 파일 하나의 크기가 단일 디스크의 용량보다 더 커질 수 있음. 
* 파일 단위보다 블록 단위로 추상화를 하면 파일 탐색 지점이나 메타정보를 저장할 때 사이즈가 고정되어 있으므로 구현이 좀 더 쉬운 이점.

![hdfs block](https://open.oss.navercorp.com/storage/user/1981/files/5b05075f-58e5-4b77-9b70-3ebf19a59692)

## DataNode
* 파일을 블록 단위로 저장하는 역할. 네임노드로 블록리포트와 하트비트를 주기적으로 보내어 블록의 변경사항을 체크하고, 네임노드의 메타데이터 갱신.
* 파일을 블록 단위로 저장할 때 각 블록은 여러 node에 복제되어 저장. 복제 수(Replication Factor)를 지정할 수 있으며 기본값은 3.
* 운영상태: 데이터노드의 업그레이드, 패치 같은 작업을 하기 위해 서비스를 잠시 멈추어야 할 경우 블록을 안전하게 보관하기 위해 설정가능.
> * NORMAL: 서비스 상태
> * DECOMMISSIONED: 서비스 중단 상태
> * DECOMMISSION_INPROGRESS: 서비스 중단 상태로 진행 중
> * IN_MAINTENANCE: 정비 상태
> * ENTERING_MAINTENANCE: 정비 상태로 진행 중

## HDFS 고가용성
* 한 개의 네임노드가 단일 실패 지점(SPOF). 네임노드에 문제가 발생하면 모든 작업이 중지되고, 파일을 읽거나 쓸수 없게됨. 버전2부터 네임노드 HA 기능 지원. 
* HDFS 고가용성은 이중화된 두대의 서버인 액티브(active) 네임노드와 스탠바이(standby) 네임노드를 이용하여 지원.
* 액티브와 스탠바이 네임노드 둘 다 데이터 노드로부터 블록 리포트와 하트비트를 모두 받아서 동일한 메타데이터를 유지하고, 공유 스토리지를 이용하여 에디트파일을 공유.
* 액티브 네임노드는 네임노드의 역할, 스탠바이 네임노드는 액티브와 동일한 메타데이터 정보를 유지하다가, 액티브에 문제가 발생하면 스탠바이 네임노드가 액티브 네임노드로 동작.
* 액티브 네임노드에 문제가 발생하는 것을 자동으로 확인하는 것이 어렵기 때문에 보통 주키퍼를 이용하여 장애 발생시 자동으로 변경.
* 스탠바이 네임노드는 세컨더리 네임노드의 역할을 동일하게 수행하므로 HDFS를 고가용성 모드로 설정하였을 때는 세컨더리 네임노드를 실행하지 않음.

## HDFS balancer
* HDFS를 운영하면서 데이터 불균형이 발생하여 밸런싱을 실행해야 하는 경우가 존재.
* 데이터 노드 추가, 대량의 데이터를 삭제 등의 경우 데이터 노드 간의 데이터 불균형 발생.
* HDFS balancer 실행을 통해 데이터 노드 간 균형을 맞출 수 있음.

## HDFS File Format
* JSON
> * 사람이 읽기 쉬운 방식. 기존의 방식(XML)에 비해 더 읽기 쉬우며 용량도 더 적다.
> * 빅데이터 처리를 할 때는 바이너리 포맷이 아니므로 처리 속도가 느리다.
* AVRO
> * 바이너리 포맷이므로 기계가 쉽게 읽을 수 있으며, 하둡에 최적화되어 여러 디스크에 분할하여 저장 가능.
> * 행 기반으로 데이터 저장되어 쓰기에 최적화된 방식.
> * 쿼리에서 Full scan이나 모든 칼럼을 다 사용할 때 적합.
* Parquet
> * AVRO처럼 바이너리 포못, 여러 디스크에 분할하여 저장 가능.
> * 열 기반으로 데이터 저장하여 데이터 읽기에 최적화된 방식. 
> * 일부 칼럼만 이용할 때 적합.